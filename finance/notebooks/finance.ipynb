{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN81AxS2RSZtLi7uzqgBLYj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUyV1kUE8EPh","executionInfo":{"status":"ok","timestamp":1670574230623,"user_tz":480,"elapsed":7193,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"c15d1e01-abb0-40d6-a974-c29e066b06f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'FinRL'...\n","remote: Enumerating objects: 11571, done.\u001b[K\n","remote: Counting objects: 100% (91/91), done.\u001b[K\n","remote: Compressing objects: 100% (67/67), done.\u001b[K\n","remote: Total 11571 (delta 48), reused 52 (delta 24), pack-reused 11480\u001b[K\n","Receiving objects: 100% (11571/11571), 75.51 MiB | 21.28 MiB/s, done.\n","Resolving deltas: 100% (7622/7622), done.\n"]}],"source":["!git clone https://github.com/AI4Finance-Foundation/FinRL.git"]},{"cell_type":"code","source":["%cd FinRL"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j_eZf30r8Hew","executionInfo":{"status":"ok","timestamp":1670577193331,"user_tz":480,"elapsed":308,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"fadb6c9c-540d-4d75-ede3-a323b618daa4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/FinRL\n"]}]},{"cell_type":"code","source":["!pip install ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"9-kQ4S0G8nI2","executionInfo":{"status":"ok","timestamp":1670577240344,"user_tz":480,"elapsed":47019,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"c89c3b3b-6607-42db-dcd6-c661d3e74d87"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing /content/FinRL\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n","  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-1bnk7l9s/elegantrl_5295c70d56824d44bf5748d23641e21f\n","  Running command git clone -q https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-1bnk7l9s/elegantrl_5295c70d56824d44bf5748d23641e21f\n","Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n","  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-1bnk7l9s/pyfolio_8b7b451ece81474fbc9aa00d81745f5c\n","  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-1bnk7l9s/pyfolio_8b7b451ece81474fbc9aa00d81745f5c\n","Requirement already satisfied: importlib-metadata==4.13.0 in /usr/local/lib/python3.8/dist-packages (from finrl==0.3.5) (4.13.0)\n","Collecting jqdatasdk\n","  Using cached jqdatasdk-1.8.11-py3-none-any.whl (158 kB)\n","Collecting exchange_calendars==3.6.3\n","  Using cached exchange_calendars-3.6.3-py3-none-any.whl\n","Collecting ray[default,tune]==1.3.0\n","  Using cached ray-1.3.0-cp38-cp38-manylinux2014_x86_64.whl (49.5 MB)\n","Collecting tensorboardX\n","  Using cached tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","Collecting gputil\n","  Using cached GPUtil-1.4.0-py3-none-any.whl\n","Collecting stable-baselines3<2.0.0,>=1.6.2\n","  Using cached stable_baselines3-1.6.2-py3-none-any.whl (170 kB)\n","Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from finrl==0.3.5) (1.0.2)\n","Collecting stockstats>=0.4.0\n","  Using cached stockstats-0.5.1-py2.py3-none-any.whl (20 kB)\n","Collecting alpaca_trade_api>=2.1.0\n","  Using cached alpaca_trade_api-2.3.0-py3-none-any.whl (33 kB)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from finrl==0.3.5) (1.21.6)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.8/dist-packages (from finrl==0.3.5) (1.3.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from finrl==0.3.5) (3.2.2)\n","Collecting lz4\n","  Using cached lz4-4.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.8/dist-packages (from finrl==0.3.5) (0.21.0)\n","Collecting ccxt>=1.66.32\n","  Using cached ccxt-2.2.90-py2.py3-none-any.whl (3.4 MB)\n","Collecting yfinance\n","  Using cached yfinance-0.1.87-py2.py3-none-any.whl (29 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.5) (1.13.0+cu116)\n","Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.8/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (7.9.0)\n","Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.8/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2022.6)\n","Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (1.7.3)\n","Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.11.2)\n","Collecting empyrical>=0.5.0\n","  Using cached empyrical-0.5.5-py3-none-any.whl\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (2.8.2)\n","Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.8/dist-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (0.3.1)\n","Collecting pyluach\n","  Using cached pyluach-2.0.2-py3-none-any.whl (22 kB)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (0.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata==4.13.0->finrl==0.3.5) (3.11.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ray[default,tune]==1.3.0->finrl==0.3.5) (1.0.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from ray[default,tune]==1.3.0->finrl==0.3.5) (6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from ray[default,tune]==1.3.0->finrl==0.3.5) (3.8.1)\n","Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ray[default,tune]==1.3.0->finrl==0.3.5) (0.3.14)\n","Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.8/dist-packages (from ray[default,tune]==1.3.0->finrl==0.3.5) (4.4.0)\n","Collecting aioredis\n","  Using cached aioredis-2.0.1-py3-none-any.whl (71 kB)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from ray[default,tune]==1.3.0->finrl==0.3.5) (0.4.6)\n","Collecting aiohttp-cors\n","  Using cached aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from ray[default,tune]==1.3.0->finrl==0.3.5) (4.3.3)\n","Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.8/dist-packages (from ray[default,tune]==1.3.0->finrl==0.3.5) (3.19.6)\n","Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.8/dist-packages (from ray[default,tune]==1.3.0->finrl==0.3.5) (1.51.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from ray[default,tune]==1.3.0->finrl==0.3.5) (2.28.1)\n","Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from ray[default,tune]==1.3.0->finrl==0.3.5) (0.15.0)\n","Requirement already satisfied: opencensus in /usr/local/lib/python3.8/dist-packages (from ray[default,tune]==1.3.0->finrl==0.3.5) (0.11.0)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from ray[default,tune]==1.3.0->finrl==0.3.5) (7.1.2)\n","Requirement already satisfied: gpustat in /usr/local/lib/python3.8/dist-packages (from ray[default,tune]==1.3.0->finrl==0.3.5) (1.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from ray[default,tune]==1.3.0->finrl==0.3.5) (3.8.0)\n","Collecting colorful\n","  Using cached colorful-0.5.5-py2.py3-none-any.whl (201 kB)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from ray[default,tune]==1.3.0->finrl==0.3.5) (0.8.10)\n","Collecting websockets<11,>=9.0\n","  Using cached websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n","Collecting deprecation==2.1.0\n","  Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n","Collecting websocket-client<2,>=0.56.0\n","  Using cached websocket_client-1.4.2-py3-none-any.whl (55 kB)\n","Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.8/dist-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.24.3)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->ray[default,tune]==1.3.0->finrl==0.3.5) (2.1.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->ray[default,tune]==1.3.0->finrl==0.3.5) (1.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->ray[default,tune]==1.3.0->finrl==0.3.5) (6.0.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->ray[default,tune]==1.3.0->finrl==0.3.5) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->ray[default,tune]==1.3.0->finrl==0.3.5) (1.8.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->ray[default,tune]==1.3.0->finrl==0.3.5) (1.3.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->ray[default,tune]==1.3.0->finrl==0.3.5) (22.1.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from deprecation==2.1.0->alpaca_trade_api>=2.1.0->finrl==0.3.5) (21.3)\n","Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.8/dist-packages (from ccxt>=1.66.32->finrl==0.3.5) (2022.9.24)\n","Collecting cryptography>=2.6.1\n","  Using cached cryptography-38.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n","Collecting aiodns>=1.1.1\n","  Using cached aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n","Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.8/dist-packages (from ccxt>=1.66.32->finrl==0.3.5) (65.6.3)\n","Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from aiodns>=1.1.1->ccxt>=1.66.32->finrl==0.3.5) (4.2.2)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=2.6.1->ccxt>=1.66.32->finrl==0.3.5) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt>=1.66.32->finrl==0.3.5) (2.21)\n","Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.8/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.9.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym>=0.17->finrl==0.3.5) (1.5.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (5.6.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.4.2)\n","Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.18.2)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2.0.10)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2.6.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.5)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.2.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.8.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->finrl==0.3.5) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->finrl==0.3.5) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->finrl==0.3.5) (3.0.9)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.9.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (1.15.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->ray[default,tune]==1.3.0->finrl==0.3.5) (2.10)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (1.2.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.5) (4.4.0)\n","Requirement already satisfied: nvidia-ml-py<=11.495.46,>=11.450.129 in /usr/local/lib/python3.8/dist-packages (from gpustat->ray[default,tune]==1.3.0->finrl==0.3.5) (11.495.46)\n","Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.8/dist-packages (from gpustat->ray[default,tune]==1.3.0->finrl==0.3.5) (1.19.1)\n","Requirement already satisfied: psutil>=5.6.0 in /usr/local/lib/python3.8/dist-packages (from gpustat->ray[default,tune]==1.3.0->finrl==0.3.5) (5.9.4)\n","Collecting box2d-py==2.3.5\n","  Using cached box2d-py-2.3.5.tar.gz (374 kB)\n","Requirement already satisfied: pyglet>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from gym>=0.17->finrl==0.3.5) (2.0.1)\n","Collecting thriftpy2>=0.3.9\n","  Using cached thriftpy2-0.4.16-cp38-cp38-linux_x86_64.whl\n","Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.8/dist-packages (from jqdatasdk->finrl==0.3.5) (1.4.44)\n","Collecting pymysql>=0.7.6\n","  Using cached PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.5) (2.0.1)\n","Requirement already satisfied: ply<4.0,>=3.4 in /usr/local/lib/python3.8/dist-packages (from thriftpy2>=0.3.9->jqdatasdk->finrl==0.3.5) (3.11)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray[default,tune]==1.3.0->finrl==0.3.5) (5.10.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray[default,tune]==1.3.0->finrl==0.3.5) (0.19.2)\n","Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from opencensus->ray[default,tune]==1.3.0->finrl==0.3.5) (2.8.2)\n","Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from opencensus->ray[default,tune]==1.3.0->finrl==0.3.5) (0.1.3)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]==1.3.0->finrl==0.3.5) (1.57.0)\n","Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]==1.3.0->finrl==0.3.5) (2.15.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]==1.3.0->finrl==0.3.5) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]==1.3.0->finrl==0.3.5) (5.2.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]==1.3.0->finrl==0.3.5) (4.9)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]==1.3.0->finrl==0.3.5) (0.4.8)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.0)\n","Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.8/dist-packages (from yfinance->finrl==0.3.5) (1.4.4)\n","Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.8/dist-packages (from yfinance->finrl==0.3.5) (0.0.11)\n","Building wheels for collected packages: finrl, elegantrl, pyfolio, box2d-py\n","  Building wheel for finrl (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for finrl: filename=finrl-0.3.5-py3-none-any.whl size=2745851 sha256=ec5cbe9a1f546336064a7459d9644e740f67424193a4b361aa89ac16ec1fa823\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-73lx5k3z/wheels/f7/87/01/43b8c8b659b380b2d0e955e3f45b55a7d30066afc250f3d554\n","  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for elegantrl: filename=elegantrl-0.3.5-py3-none-any.whl size=363011 sha256=83f5e6cfbe684f02edfbbc0e9c4fdd86fed646d664597e77444a33a1cf6ba08b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-73lx5k3z/wheels/d6/fb/88/7d5e5490b35f78191267fee312ce81baac55c6b9d89151e72a\n","  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75760 sha256=4aef011a848f4619e3f0ed9433d145c6924da89b1fb8b9aea5067d0c6627d5fc\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-73lx5k3z/wheels/7b/59/8b/3c276a18b58c04a1fd0e1351e979fb5396f93fbde5b5438df1\n","  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\n","\u001b[?25h  Running setup.py clean for box2d-py\n","Successfully built finrl elegantrl pyfolio\n","Failed to build box2d-py\n","Installing collected packages: box2d-py, aioredis, aiohttp-cors, websockets, websocket-client, thriftpy2, tensorboardX, ray, pymysql, pyluach, empyrical, deprecation, cryptography, colorful, aiodns, yfinance, stockstats, stable-baselines3, pyfolio, lz4, jqdatasdk, gputil, exchange-calendars, elegantrl, ccxt, alpaca-trade-api, finrl\n","    Running setup.py install for box2d-py ... \u001b[?25l\u001b[?25herror\n","\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-1bnk7l9s/box2d-py_b9b8cdab35c34ff0964dff4d7b447cc2/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-1bnk7l9s/box2d-py_b9b8cdab35c34ff0964dff4d7b447cc2/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-1gctz_8e/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.8/box2d-py Check the logs for full command output.\u001b[0m\n"]}]},{"cell_type":"code","source":["%run Stock_NeurIPS2018_SB3.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Dq30-iV18seW","executionInfo":{"status":"error","timestamp":1668562059994,"user_tz":480,"elapsed":1088226,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"83b9a666-754b-4030-cdc8-24d0d905276d"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n","  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"]},{"output_type":"stream","name":"stdout","text":["[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","Shape of DataFrame:  (101261, 8)\n","config_tickers.DOW_30_TICKER: ['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n","df.shape: (101261, 8)\n","Successfully added technical indicators\n","[*********************100%***********************]  1 of 1 completed\n","Shape of DataFrame:  (3460, 8)\n","Successfully added vix\n","Successfully added turbulence index\n","len(train): 83897\n","len(trade): 9773\n","train.tail():             date  tic        open        high         low       close  \\\n","2892  2020-06-30  UNH  288.570007  296.450012  287.660004  285.857239   \n","2892  2020-06-30    V  191.490005  193.750000  190.160004  189.975372   \n","2892  2020-06-30   VZ   54.919998   55.290001   54.360001   48.926273   \n","2892  2020-06-30  WBA   42.119999   42.580002   41.759998   38.128487   \n","2892  2020-06-30  WMT  119.220001  120.129997  118.540001  115.618233   \n","\n","          volume  day      macd     boll_ub     boll_lb     rsi_30     cci_30  \\\n","2892   2932900.0  1.0 -0.019349  301.898619  269.441905  52.413050 -25.890798   \n","2892   9040100.0  1.0  1.044596  197.956663  184.302276  53.021032 -51.589487   \n","2892  17414800.0  1.0 -0.424525   52.365979   47.326289  48.097040 -51.128381   \n","2892   4782100.0  1.0 -0.082034   41.619005   35.639081  48.830183 -14.575656   \n","2892   6836400.0  1.0 -0.882725  118.955684  113.018223  48.159686 -69.952580   \n","\n","         dx_30  close_30_sma  close_60_sma        atr        tema    vix  \\\n","2892  1.846804    286.099506    279.127075  14.858707  283.978886  30.43   \n","2892  2.013358    190.720189    180.952008   6.439931  188.986222  30.43   \n","2892  8.508886     49.543359     49.982885   6.719387   48.611979  30.43   \n","2892  1.500723     38.225630     38.030220   5.056654   37.986633  30.43   \n","2892  3.847271    117.276856    119.204111   5.298769  115.234656  30.43   \n","\n","      turbulence  \n","2892   12.918861  \n","2892   12.918861  \n","2892   12.918861  \n","2892   12.918861  \n","2892   12.918861  \n","trade.head():          date   tic        open        high         low       close  \\\n","0  2020-07-01  AAPL   91.279999   91.839996   90.977501   89.631210   \n","0  2020-07-01  AMGN  235.520004  256.230011  232.580002  238.313568   \n","0  2020-07-01   AXP   95.250000   96.959999   93.639999   91.394157   \n","0  2020-07-01    BA  185.880005  190.610001  180.039993  180.320007   \n","0  2020-07-01   CAT  129.380005  129.399994  125.879997  119.020714   \n","\n","        volume  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n","0  110737200.0  2.0  3.005436   92.417425   79.936132  62.807142  107.496672   \n","0    6575800.0  2.0  3.608526  230.616460  198.678635  61.279652  271.208776   \n","0    3301000.0  2.0 -0.386236  109.593883   87.099642  48.504815  -66.313257   \n","0   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   24.220608   \n","0    2807800.0  2.0  1.255425  128.858560  111.820860  52.865419   35.668231   \n","\n","       dx_30  close_30_sma  close_60_sma        atr        tema        vix  \\\n","0  29.730532     83.678530     77.481209   2.896537   89.621015  28.620001   \n","0  46.806139    213.212110    214.276892  19.759237  232.599971  28.620001   \n","0   3.142448     96.513644     90.013762   5.311152   91.211788  28.620001   \n","0  15.932920    176.472335    155.614168  13.520082  182.210854  28.620001   \n","0  14.457404    117.798663    112.110446   8.944440  119.151878  28.620001   \n","\n","   turbulence  \n","0   53.068141  \n","0   53.068141  \n","0   53.068141  \n","0   53.068141  \n","0   53.068141  \n","config.INDICATORS: ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma', 'atr', 'tema']\n","Stock Dimension: 29, State Space: 349\n","type(env_train): <class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n","{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n","Using cpu device\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 102        |\n","|    iterations         | 100        |\n","|    time_elapsed       | 4          |\n","|    total_timesteps    | 500        |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | 0.846      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 99         |\n","|    policy_loss        | 10.9       |\n","|    reward             | 0.08833885 |\n","|    std                | 1.01       |\n","|    value_loss         | 0.0968     |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 103        |\n","|    iterations         | 200        |\n","|    time_elapsed       | 9          |\n","|    total_timesteps    | 1000       |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | 1.19e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 199        |\n","|    policy_loss        | -9.35      |\n","|    reward             | -0.7199985 |\n","|    std                | 1.01       |\n","|    value_loss         | 0.639      |\n","--------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 103      |\n","|    iterations         | 300      |\n","|    time_elapsed       | 14       |\n","|    total_timesteps    | 1500     |\n","| train/                |          |\n","|    entropy_loss       | -41.4    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 299      |\n","|    policy_loss        | -263     |\n","|    reward             | 6.157881 |\n","|    std                | 1.01     |\n","|    value_loss         | 52.2     |\n","------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 94        |\n","|    iterations         | 400       |\n","|    time_elapsed       | 21        |\n","|    total_timesteps    | 2000      |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | 0.0197    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 399       |\n","|    policy_loss        | -97.7     |\n","|    reward             | 1.3537548 |\n","|    std                | 1.01      |\n","|    value_loss         | 12.3      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 95         |\n","|    iterations         | 500        |\n","|    time_elapsed       | 26         |\n","|    total_timesteps    | 2500       |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 499        |\n","|    policy_loss        | 297        |\n","|    reward             | -7.5883374 |\n","|    std                | 1.01       |\n","|    value_loss         | 61.1       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 94          |\n","|    iterations         | 600         |\n","|    time_elapsed       | 31          |\n","|    total_timesteps    | 3000        |\n","| train/                |             |\n","|    entropy_loss       | -41.4       |\n","|    explained_variance | -0.00359    |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 599         |\n","|    policy_loss        | 201         |\n","|    reward             | 0.026560089 |\n","|    std                | 1.01        |\n","|    value_loss         | 23.9        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 95         |\n","|    iterations         | 700        |\n","|    time_elapsed       | 36         |\n","|    total_timesteps    | 3500       |\n","| train/                |            |\n","|    entropy_loss       | -41.5      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 699        |\n","|    policy_loss        | 9.33       |\n","|    reward             | -3.8237581 |\n","|    std                | 1.01       |\n","|    value_loss         | 0.663      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 96         |\n","|    iterations         | 800        |\n","|    time_elapsed       | 41         |\n","|    total_timesteps    | 4000       |\n","| train/                |            |\n","|    entropy_loss       | -41.5      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 799        |\n","|    policy_loss        | -127       |\n","|    reward             | -1.9221157 |\n","|    std                | 1.01       |\n","|    value_loss         | 11.2       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 96         |\n","|    iterations         | 900        |\n","|    time_elapsed       | 46         |\n","|    total_timesteps    | 4500       |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | 5.42e-06   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 899        |\n","|    policy_loss        | 130        |\n","|    reward             | 0.25302905 |\n","|    std                | 1.01       |\n","|    value_loss         | 12.7       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 1000       |\n","|    time_elapsed       | 51         |\n","|    total_timesteps    | 5000       |\n","| train/                |            |\n","|    entropy_loss       | -41.5      |\n","|    explained_variance | 1.19e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 999        |\n","|    policy_loss        | -58.4      |\n","|    reward             | -3.7827024 |\n","|    std                | 1.01       |\n","|    value_loss         | 3.23       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 98        |\n","|    iterations         | 1100      |\n","|    time_elapsed       | 55        |\n","|    total_timesteps    | 5500      |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1099      |\n","|    policy_loss        | -228      |\n","|    reward             | 2.9309185 |\n","|    std                | 1.01      |\n","|    value_loss         | 35.2      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 98         |\n","|    iterations         | 1200       |\n","|    time_elapsed       | 60         |\n","|    total_timesteps    | 6000       |\n","| train/                |            |\n","|    entropy_loss       | -41.5      |\n","|    explained_variance | 0.181      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1199       |\n","|    policy_loss        | -147       |\n","|    reward             | 0.11953256 |\n","|    std                | 1.01       |\n","|    value_loss         | 13.8       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 98         |\n","|    iterations         | 1300       |\n","|    time_elapsed       | 65         |\n","|    total_timesteps    | 6500       |\n","| train/                |            |\n","|    entropy_loss       | -41.5      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1299       |\n","|    policy_loss        | -32.4      |\n","|    reward             | -3.1845903 |\n","|    std                | 1.01       |\n","|    value_loss         | 2.48       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 98          |\n","|    iterations         | 1400        |\n","|    time_elapsed       | 71          |\n","|    total_timesteps    | 7000        |\n","| train/                |             |\n","|    entropy_loss       | -41.5       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 1399        |\n","|    policy_loss        | 142         |\n","|    reward             | -0.72316474 |\n","|    std                | 1.01        |\n","|    value_loss         | 14.7        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 98        |\n","|    iterations         | 1500      |\n","|    time_elapsed       | 76        |\n","|    total_timesteps    | 7500      |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1499      |\n","|    policy_loss        | -310      |\n","|    reward             | 1.1360862 |\n","|    std                | 1.01      |\n","|    value_loss         | 104       |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 96         |\n","|    iterations         | 1600       |\n","|    time_elapsed       | 82         |\n","|    total_timesteps    | 8000       |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | 5.96e-08   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1599       |\n","|    policy_loss        | 389        |\n","|    reward             | 0.12919222 |\n","|    std                | 1.01       |\n","|    value_loss         | 106        |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 1700       |\n","|    time_elapsed       | 87         |\n","|    total_timesteps    | 8500       |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1699       |\n","|    policy_loss        | -26.6      |\n","|    reward             | 0.45939845 |\n","|    std                | 1.01       |\n","|    value_loss         | 24.4       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 1800      |\n","|    time_elapsed       | 92        |\n","|    total_timesteps    | 9000      |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1799      |\n","|    policy_loss        | 8.41      |\n","|    reward             | 1.7382538 |\n","|    std                | 1.01      |\n","|    value_loss         | 0.15      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 1900      |\n","|    time_elapsed       | 97        |\n","|    total_timesteps    | 9500      |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1899      |\n","|    policy_loss        | -46.8     |\n","|    reward             | 0.8677148 |\n","|    std                | 1.01      |\n","|    value_loss         | 2.38      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 2000       |\n","|    time_elapsed       | 102        |\n","|    total_timesteps    | 10000      |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1999       |\n","|    policy_loss        | -101       |\n","|    reward             | 0.30083293 |\n","|    std                | 1.01       |\n","|    value_loss         | 7.09       |\n","--------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 97       |\n","|    iterations         | 2100     |\n","|    time_elapsed       | 107      |\n","|    total_timesteps    | 10500    |\n","| train/                |          |\n","|    entropy_loss       | -41.3    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 2099     |\n","|    policy_loss        | -61.9    |\n","|    reward             | 2.48141  |\n","|    std                | 1.01     |\n","|    value_loss         | 4.02     |\n","------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 98         |\n","|    iterations         | 2200       |\n","|    time_elapsed       | 111        |\n","|    total_timesteps    | 11000      |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2199       |\n","|    policy_loss        | -60        |\n","|    reward             | -6.1962504 |\n","|    std                | 1.01       |\n","|    value_loss         | 8.67       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 98        |\n","|    iterations         | 2300      |\n","|    time_elapsed       | 116       |\n","|    total_timesteps    | 11500     |\n","| train/                |           |\n","|    entropy_loss       | -41.3     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2299      |\n","|    policy_loss        | -2.55e+03 |\n","|    reward             | 12.338681 |\n","|    std                | 1.01      |\n","|    value_loss         | 3.82e+03  |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 98         |\n","|    iterations         | 2400       |\n","|    time_elapsed       | 121        |\n","|    total_timesteps    | 12000      |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | -0.0134    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2399       |\n","|    policy_loss        | 116        |\n","|    reward             | 0.45407006 |\n","|    std                | 1.01       |\n","|    value_loss         | 16.5       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 99         |\n","|    iterations         | 2500       |\n","|    time_elapsed       | 126        |\n","|    total_timesteps    | 12500      |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | -0.000758  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2499       |\n","|    policy_loss        | -75        |\n","|    reward             | 0.84079087 |\n","|    std                | 1.01       |\n","|    value_loss         | 3.52       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 99        |\n","|    iterations         | 2600      |\n","|    time_elapsed       | 131       |\n","|    total_timesteps    | 13000     |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | -2.38e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2599      |\n","|    policy_loss        | -10.4     |\n","|    reward             | 1.4816694 |\n","|    std                | 1.01      |\n","|    value_loss         | 0.162     |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 99         |\n","|    iterations         | 2700       |\n","|    time_elapsed       | 135        |\n","|    total_timesteps    | 13500      |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | -2.38e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2699       |\n","|    policy_loss        | -53.9      |\n","|    reward             | -0.8608802 |\n","|    std                | 1.01       |\n","|    value_loss         | 3.13       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 98        |\n","|    iterations         | 2800      |\n","|    time_elapsed       | 141       |\n","|    total_timesteps    | 14000     |\n","| train/                |           |\n","|    entropy_loss       | -41.3     |\n","|    explained_variance | -0.000504 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2799      |\n","|    policy_loss        | 246       |\n","|    reward             | 1.7071589 |\n","|    std                | 1.01      |\n","|    value_loss         | 40.9      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 98        |\n","|    iterations         | 2900      |\n","|    time_elapsed       | 147       |\n","|    total_timesteps    | 14500     |\n","| train/                |           |\n","|    entropy_loss       | -41.3     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2899      |\n","|    policy_loss        | -70.6     |\n","|    reward             | 1.3467995 |\n","|    std                | 1.01      |\n","|    value_loss         | 2.81      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 98        |\n","|    iterations         | 3000      |\n","|    time_elapsed       | 152       |\n","|    total_timesteps    | 15000     |\n","| train/                |           |\n","|    entropy_loss       | -41.3     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2999      |\n","|    policy_loss        | 150       |\n","|    reward             | 0.8633069 |\n","|    std                | 1.01      |\n","|    value_loss         | 14.3      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 98         |\n","|    iterations         | 3100       |\n","|    time_elapsed       | 157        |\n","|    total_timesteps    | 15500      |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | 1.19e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3099       |\n","|    policy_loss        | 7.13       |\n","|    reward             | -1.2357732 |\n","|    std                | 1.01       |\n","|    value_loss         | 1.17       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 98         |\n","|    iterations         | 3200       |\n","|    time_elapsed       | 161        |\n","|    total_timesteps    | 16000      |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3199       |\n","|    policy_loss        | -32.2      |\n","|    reward             | -1.2571691 |\n","|    std                | 1.01       |\n","|    value_loss         | 9.94       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 99         |\n","|    iterations         | 3300       |\n","|    time_elapsed       | 166        |\n","|    total_timesteps    | 16500      |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3299       |\n","|    policy_loss        | 59.7       |\n","|    reward             | -0.8284877 |\n","|    std                | 1.01       |\n","|    value_loss         | 3.39       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 98        |\n","|    iterations         | 3400      |\n","|    time_elapsed       | 172       |\n","|    total_timesteps    | 17000     |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3399      |\n","|    policy_loss        | 52.1      |\n","|    reward             | 2.0994756 |\n","|    std                | 1.01      |\n","|    value_loss         | 8.27      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 98         |\n","|    iterations         | 3500       |\n","|    time_elapsed       | 177        |\n","|    total_timesteps    | 17500      |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3499       |\n","|    policy_loss        | 221        |\n","|    reward             | -0.8475029 |\n","|    std                | 1.01       |\n","|    value_loss         | 29.2       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 98        |\n","|    iterations         | 3600      |\n","|    time_elapsed       | 182       |\n","|    total_timesteps    | 18000     |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3599      |\n","|    policy_loss        | -94.2     |\n","|    reward             | 2.6906826 |\n","|    std                | 1.01      |\n","|    value_loss         | 10.4      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 98        |\n","|    iterations         | 3700      |\n","|    time_elapsed       | 186       |\n","|    total_timesteps    | 18500     |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | -0.0184   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3699      |\n","|    policy_loss        | 248       |\n","|    reward             | 0.9168562 |\n","|    std                | 1.01      |\n","|    value_loss         | 44.5      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 99         |\n","|    iterations         | 3800       |\n","|    time_elapsed       | 191        |\n","|    total_timesteps    | 19000      |\n","| train/                |            |\n","|    entropy_loss       | -41.5      |\n","|    explained_variance | 1.19e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3799       |\n","|    policy_loss        | 149        |\n","|    reward             | 0.62186366 |\n","|    std                | 1.01       |\n","|    value_loss         | 14.2       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 99        |\n","|    iterations         | 3900      |\n","|    time_elapsed       | 196       |\n","|    total_timesteps    | 19500     |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3899      |\n","|    policy_loss        | 38.5      |\n","|    reward             | 1.787578  |\n","|    std                | 1.01      |\n","|    value_loss         | 5.75      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 99        |\n","|    iterations         | 4000      |\n","|    time_elapsed       | 201       |\n","|    total_timesteps    | 20000     |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3999      |\n","|    policy_loss        | 59.2      |\n","|    reward             | 1.9088264 |\n","|    std                | 1.01      |\n","|    value_loss         | 5.53      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 99         |\n","|    iterations         | 4100       |\n","|    time_elapsed       | 206        |\n","|    total_timesteps    | 20500      |\n","| train/                |            |\n","|    entropy_loss       | -41.6      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4099       |\n","|    policy_loss        | 7.51       |\n","|    reward             | 0.12752353 |\n","|    std                | 1.02       |\n","|    value_loss         | 0.911      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 98         |\n","|    iterations         | 4200       |\n","|    time_elapsed       | 212        |\n","|    total_timesteps    | 21000      |\n","| train/                |            |\n","|    entropy_loss       | -41.6      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4199       |\n","|    policy_loss        | -70.7      |\n","|    reward             | 0.39154318 |\n","|    std                | 1.02       |\n","|    value_loss         | 3.53       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 98        |\n","|    iterations         | 4300      |\n","|    time_elapsed       | 218       |\n","|    total_timesteps    | 21500     |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 4299      |\n","|    policy_loss        | -12.8     |\n","|    reward             | 4.1173644 |\n","|    std                | 1.02      |\n","|    value_loss         | 1.14      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 98        |\n","|    iterations         | 4400      |\n","|    time_elapsed       | 223       |\n","|    total_timesteps    | 22000     |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 4399      |\n","|    policy_loss        | 112       |\n","|    reward             | 1.6858947 |\n","|    std                | 1.01      |\n","|    value_loss         | 17.2      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 98        |\n","|    iterations         | 4500      |\n","|    time_elapsed       | 228       |\n","|    total_timesteps    | 22500     |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 4499      |\n","|    policy_loss        | 500       |\n","|    reward             | 1.1387997 |\n","|    std                | 1.02      |\n","|    value_loss         | 127       |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 98        |\n","|    iterations         | 4600      |\n","|    time_elapsed       | 233       |\n","|    total_timesteps    | 23000     |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 4599      |\n","|    policy_loss        | 134       |\n","|    reward             | 4.0079303 |\n","|    std                | 1.02      |\n","|    value_loss         | 11.9      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 98         |\n","|    iterations         | 4700       |\n","|    time_elapsed       | 237        |\n","|    total_timesteps    | 23500      |\n","| train/                |            |\n","|    entropy_loss       | -41.6      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4699       |\n","|    policy_loss        | -99.3      |\n","|    reward             | 0.14280629 |\n","|    std                | 1.02       |\n","|    value_loss         | 9.42       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 98         |\n","|    iterations         | 4800       |\n","|    time_elapsed       | 242        |\n","|    total_timesteps    | 24000      |\n","| train/                |            |\n","|    entropy_loss       | -41.7      |\n","|    explained_variance | 0.0497     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4799       |\n","|    policy_loss        | -60.6      |\n","|    reward             | -0.4521185 |\n","|    std                | 1.02       |\n","|    value_loss         | 3          |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 99         |\n","|    iterations         | 4900       |\n","|    time_elapsed       | 247        |\n","|    total_timesteps    | 24500      |\n","| train/                |            |\n","|    entropy_loss       | -41.6      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4899       |\n","|    policy_loss        | -96        |\n","|    reward             | 0.12317135 |\n","|    std                | 1.02       |\n","|    value_loss         | 9.06       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 99        |\n","|    iterations         | 5000      |\n","|    time_elapsed       | 251       |\n","|    total_timesteps    | 25000     |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 4999      |\n","|    policy_loss        | -167      |\n","|    reward             | -4.069479 |\n","|    std                | 1.02      |\n","|    value_loss         | 19.5      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 99        |\n","|    iterations         | 5100      |\n","|    time_elapsed       | 256       |\n","|    total_timesteps    | 25500     |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 5099      |\n","|    policy_loss        | -64.1     |\n","|    reward             | 0.8951378 |\n","|    std                | 1.02      |\n","|    value_loss         | 34.2      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 99        |\n","|    iterations         | 5200      |\n","|    time_elapsed       | 261       |\n","|    total_timesteps    | 26000     |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 5199      |\n","|    policy_loss        | -558      |\n","|    reward             | 2.6475437 |\n","|    std                | 1.02      |\n","|    value_loss         | 207       |\n","-------------------------------------\n","day: 2892, episode: 10\n","begin_total_asset: 1000000.00\n","end_total_asset: 5487936.94\n","total_reward: 4487936.94\n","total_cost: 28457.22\n","total_trades: 49515\n","Sharpe: 1.015\n","=================================\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 99         |\n","|    iterations         | 5300       |\n","|    time_elapsed       | 266        |\n","|    total_timesteps    | 26500      |\n","| train/                |            |\n","|    entropy_loss       | -41.6      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5299       |\n","|    policy_loss        | -76.5      |\n","|    reward             | 0.41811183 |\n","|    std                | 1.02       |\n","|    value_loss         | 3.62       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 99         |\n","|    iterations         | 5400       |\n","|    time_elapsed       | 272        |\n","|    total_timesteps    | 27000      |\n","| train/                |            |\n","|    entropy_loss       | -41.7      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5399       |\n","|    policy_loss        | -243       |\n","|    reward             | -0.9415566 |\n","|    std                | 1.02       |\n","|    value_loss         | 31.8       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 99        |\n","|    iterations         | 5500      |\n","|    time_elapsed       | 277       |\n","|    total_timesteps    | 27500     |\n","| train/                |           |\n","|    entropy_loss       | -41.7     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 5499      |\n","|    policy_loss        | -143      |\n","|    reward             | 1.2092541 |\n","|    std                | 1.02      |\n","|    value_loss         | 25.6      |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 99          |\n","|    iterations         | 5600        |\n","|    time_elapsed       | 282         |\n","|    total_timesteps    | 28000       |\n","| train/                |             |\n","|    entropy_loss       | -41.6       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 5599        |\n","|    policy_loss        | -73.9       |\n","|    reward             | -0.16847351 |\n","|    std                | 1.02        |\n","|    value_loss         | 8.75        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 99         |\n","|    iterations         | 5700       |\n","|    time_elapsed       | 286        |\n","|    total_timesteps    | 28500      |\n","| train/                |            |\n","|    entropy_loss       | -41.7      |\n","|    explained_variance | 5.96e-08   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5699       |\n","|    policy_loss        | 131        |\n","|    reward             | -1.7700194 |\n","|    std                | 1.02       |\n","|    value_loss         | 12.2       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 99         |\n","|    iterations         | 5800       |\n","|    time_elapsed       | 291        |\n","|    total_timesteps    | 29000      |\n","| train/                |            |\n","|    entropy_loss       | -41.7      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5799       |\n","|    policy_loss        | -16        |\n","|    reward             | 0.64950025 |\n","|    std                | 1.02       |\n","|    value_loss         | 2.34       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 99          |\n","|    iterations         | 5900        |\n","|    time_elapsed       | 296         |\n","|    total_timesteps    | 29500       |\n","| train/                |             |\n","|    entropy_loss       | -41.7       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 5899        |\n","|    policy_loss        | 6.1         |\n","|    reward             | -0.47791868 |\n","|    std                | 1.02        |\n","|    value_loss         | 0.191       |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 99        |\n","|    iterations         | 6000      |\n","|    time_elapsed       | 300       |\n","|    total_timesteps    | 30000     |\n","| train/                |           |\n","|    entropy_loss       | -41.8     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 5999      |\n","|    policy_loss        | 62.5      |\n","|    reward             | 1.2763981 |\n","|    std                | 1.02      |\n","|    value_loss         | 3.59      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 99         |\n","|    iterations         | 6100       |\n","|    time_elapsed       | 305        |\n","|    total_timesteps    | 30500      |\n","| train/                |            |\n","|    entropy_loss       | -41.7      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 6099       |\n","|    policy_loss        | 116        |\n","|    reward             | -1.4816289 |\n","|    std                | 1.02       |\n","|    value_loss         | 10.6       |\n","--------------------------------------\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 99           |\n","|    iterations         | 6200         |\n","|    time_elapsed       | 310          |\n","|    total_timesteps    | 31000        |\n","| train/                |              |\n","|    entropy_loss       | -41.7        |\n","|    explained_variance | -1.19e-07    |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 6199         |\n","|    policy_loss        | -24.2        |\n","|    reward             | -0.120165735 |\n","|    std                | 1.02         |\n","|    value_loss         | 0.654        |\n","----------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 99        |\n","|    iterations         | 6300      |\n","|    time_elapsed       | 315       |\n","|    total_timesteps    | 31500     |\n","| train/                |           |\n","|    entropy_loss       | -41.8     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6299      |\n","|    policy_loss        | 120       |\n","|    reward             | 2.7111351 |\n","|    std                | 1.02      |\n","|    value_loss         | 12.3      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 100       |\n","|    iterations         | 6400      |\n","|    time_elapsed       | 319       |\n","|    total_timesteps    | 32000     |\n","| train/                |           |\n","|    entropy_loss       | -41.8     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6399      |\n","|    policy_loss        | -24.9     |\n","|    reward             | 2.1673152 |\n","|    std                | 1.02      |\n","|    value_loss         | 0.526     |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 100      |\n","|    iterations         | 6500     |\n","|    time_elapsed       | 324      |\n","|    total_timesteps    | 32500    |\n","| train/                |          |\n","|    entropy_loss       | -41.9    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 6499     |\n","|    policy_loss        | -24.8    |\n","|    reward             | -4.10245 |\n","|    std                | 1.03     |\n","|    value_loss         | 1.98     |\n","------------------------------------\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 100          |\n","|    iterations         | 6600         |\n","|    time_elapsed       | 329          |\n","|    total_timesteps    | 33000        |\n","| train/                |              |\n","|    entropy_loss       | -41.9        |\n","|    explained_variance | 5.96e-08     |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 6599         |\n","|    policy_loss        | -55.3        |\n","|    reward             | -0.020365452 |\n","|    std                | 1.03         |\n","|    value_loss         | 3.12         |\n","----------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 99        |\n","|    iterations         | 6700      |\n","|    time_elapsed       | 335       |\n","|    total_timesteps    | 33500     |\n","| train/                |           |\n","|    entropy_loss       | -41.9     |\n","|    explained_variance | 0.0165    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6699      |\n","|    policy_loss        | -625      |\n","|    reward             | -4.157869 |\n","|    std                | 1.03      |\n","|    value_loss         | 260       |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 99        |\n","|    iterations         | 6800      |\n","|    time_elapsed       | 340       |\n","|    total_timesteps    | 34000     |\n","| train/                |           |\n","|    entropy_loss       | -41.9     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6799      |\n","|    policy_loss        | -195      |\n","|    reward             | 1.0512096 |\n","|    std                | 1.03      |\n","|    value_loss         | 22.3      |\n","-------------------------------------\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 99           |\n","|    iterations         | 6900         |\n","|    time_elapsed       | 345          |\n","|    total_timesteps    | 34500        |\n","| train/                |              |\n","|    entropy_loss       | -41.9        |\n","|    explained_variance | 0            |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 6899         |\n","|    policy_loss        | 694          |\n","|    reward             | -0.082949415 |\n","|    std                | 1.03         |\n","|    value_loss         | 253          |\n","----------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 99         |\n","|    iterations         | 7000       |\n","|    time_elapsed       | 350        |\n","|    total_timesteps    | 35000      |\n","| train/                |            |\n","|    entropy_loss       | -41.9      |\n","|    explained_variance | 1.19e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 6999       |\n","|    policy_loss        | 2.41       |\n","|    reward             | 0.11259063 |\n","|    std                | 1.03       |\n","|    value_loss         | 0.245      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 100        |\n","|    iterations         | 7100       |\n","|    time_elapsed       | 354        |\n","|    total_timesteps    | 35500      |\n","| train/                |            |\n","|    entropy_loss       | -42        |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 7099       |\n","|    policy_loss        | 26.1       |\n","|    reward             | -0.1170019 |\n","|    std                | 1.03       |\n","|    value_loss         | 1.22       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 100         |\n","|    iterations         | 7200        |\n","|    time_elapsed       | 359         |\n","|    total_timesteps    | 36000       |\n","| train/                |             |\n","|    entropy_loss       | -42         |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 7199        |\n","|    policy_loss        | -196        |\n","|    reward             | -0.12338823 |\n","|    std                | 1.03        |\n","|    value_loss         | 23.7        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 100        |\n","|    iterations         | 7300       |\n","|    time_elapsed       | 363        |\n","|    total_timesteps    | 36500      |\n","| train/                |            |\n","|    entropy_loss       | -42        |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 7299       |\n","|    policy_loss        | 97.7       |\n","|    reward             | 0.72768295 |\n","|    std                | 1.03       |\n","|    value_loss         | 8.09       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 100       |\n","|    iterations         | 7400      |\n","|    time_elapsed       | 368       |\n","|    total_timesteps    | 37000     |\n","| train/                |           |\n","|    entropy_loss       | -42       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 7399      |\n","|    policy_loss        | 240       |\n","|    reward             | -4.874453 |\n","|    std                | 1.03      |\n","|    value_loss         | 51        |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 100      |\n","|    iterations         | 7500     |\n","|    time_elapsed       | 373      |\n","|    total_timesteps    | 37500    |\n","| train/                |          |\n","|    entropy_loss       | -42.1    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 7499     |\n","|    policy_loss        | -122     |\n","|    reward             | 4.189405 |\n","|    std                | 1.03     |\n","|    value_loss         | 10.3     |\n","------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 100       |\n","|    iterations         | 7600      |\n","|    time_elapsed       | 377       |\n","|    total_timesteps    | 38000     |\n","| train/                |           |\n","|    entropy_loss       | -42.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 7599      |\n","|    policy_loss        | -83.4     |\n","|    reward             | 1.5923005 |\n","|    std                | 1.04      |\n","|    value_loss         | 5         |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 100        |\n","|    iterations         | 7700       |\n","|    time_elapsed       | 382        |\n","|    total_timesteps    | 38500      |\n","| train/                |            |\n","|    entropy_loss       | -42.1      |\n","|    explained_variance | -0.00406   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 7699       |\n","|    policy_loss        | 83.4       |\n","|    reward             | 0.38846377 |\n","|    std                | 1.03       |\n","|    value_loss         | 6.5        |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 100       |\n","|    iterations         | 7800      |\n","|    time_elapsed       | 387       |\n","|    total_timesteps    | 39000     |\n","| train/                |           |\n","|    entropy_loss       | -42.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 7799      |\n","|    policy_loss        | 45.9      |\n","|    reward             | 0.7778313 |\n","|    std                | 1.04      |\n","|    value_loss         | 1.49      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 100       |\n","|    iterations         | 7900      |\n","|    time_elapsed       | 391       |\n","|    total_timesteps    | 39500     |\n","| train/                |           |\n","|    entropy_loss       | -42.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 7899      |\n","|    policy_loss        | 140       |\n","|    reward             | 1.5026774 |\n","|    std                | 1.04      |\n","|    value_loss         | 15.2      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 100       |\n","|    iterations         | 8000      |\n","|    time_elapsed       | 398       |\n","|    total_timesteps    | 40000     |\n","| train/                |           |\n","|    entropy_loss       | -42.1     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 7999      |\n","|    policy_loss        | 148       |\n","|    reward             | 1.1648179 |\n","|    std                | 1.04      |\n","|    value_loss         | 21.4      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 100       |\n","|    iterations         | 8100      |\n","|    time_elapsed       | 402       |\n","|    total_timesteps    | 40500     |\n","| train/                |           |\n","|    entropy_loss       | -42.1     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8099      |\n","|    policy_loss        | 353       |\n","|    reward             | 2.6292186 |\n","|    std                | 1.04      |\n","|    value_loss         | 78.1      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 100       |\n","|    iterations         | 8200      |\n","|    time_elapsed       | 407       |\n","|    total_timesteps    | 41000     |\n","| train/                |           |\n","|    entropy_loss       | -42.2     |\n","|    explained_variance | -7.36e-05 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8199      |\n","|    policy_loss        | 14.5      |\n","|    reward             | 0.6717679 |\n","|    std                | 1.04      |\n","|    value_loss         | 0.165     |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 100        |\n","|    iterations         | 8300       |\n","|    time_elapsed       | 412        |\n","|    total_timesteps    | 41500      |\n","| train/                |            |\n","|    entropy_loss       | -42.2      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 8299       |\n","|    policy_loss        | -253       |\n","|    reward             | -2.3772063 |\n","|    std                | 1.04       |\n","|    value_loss         | 39.7       |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 100         |\n","|    iterations         | 8400        |\n","|    time_elapsed       | 416         |\n","|    total_timesteps    | 42000       |\n","| train/                |             |\n","|    entropy_loss       | -42.2       |\n","|    explained_variance | 5.96e-08    |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 8399        |\n","|    policy_loss        | -105        |\n","|    reward             | 0.080739856 |\n","|    std                | 1.04        |\n","|    value_loss         | 9.4         |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 100        |\n","|    iterations         | 8500       |\n","|    time_elapsed       | 421        |\n","|    total_timesteps    | 42500      |\n","| train/                |            |\n","|    entropy_loss       | -42.3      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 8499       |\n","|    policy_loss        | -62.7      |\n","|    reward             | -0.7711144 |\n","|    std                | 1.04       |\n","|    value_loss         | 3.66       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 100       |\n","|    iterations         | 8600      |\n","|    time_elapsed       | 426       |\n","|    total_timesteps    | 43000     |\n","| train/                |           |\n","|    entropy_loss       | -42.3     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8599      |\n","|    policy_loss        | -18.2     |\n","|    reward             | -8.558888 |\n","|    std                | 1.04      |\n","|    value_loss         | 8.71      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 100       |\n","|    iterations         | 8700      |\n","|    time_elapsed       | 431       |\n","|    total_timesteps    | 43500     |\n","| train/                |           |\n","|    entropy_loss       | -42.3     |\n","|    explained_variance | 0.0728    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8699      |\n","|    policy_loss        | 12.5      |\n","|    reward             | 1.5586292 |\n","|    std                | 1.04      |\n","|    value_loss         | 0.938     |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 100        |\n","|    iterations         | 8800       |\n","|    time_elapsed       | 437        |\n","|    total_timesteps    | 44000      |\n","| train/                |            |\n","|    entropy_loss       | -42.3      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 8799       |\n","|    policy_loss        | -58.7      |\n","|    reward             | 0.50997066 |\n","|    std                | 1.04       |\n","|    value_loss         | 2.32       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 100       |\n","|    iterations         | 8900      |\n","|    time_elapsed       | 442       |\n","|    total_timesteps    | 44500     |\n","| train/                |           |\n","|    entropy_loss       | -42.4     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8899      |\n","|    policy_loss        | -46.2     |\n","|    reward             | 1.9391919 |\n","|    std                | 1.05      |\n","|    value_loss         | 2.52      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 100        |\n","|    iterations         | 9000       |\n","|    time_elapsed       | 447        |\n","|    total_timesteps    | 45000      |\n","| train/                |            |\n","|    entropy_loss       | -42.4      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 8999       |\n","|    policy_loss        | -14.9      |\n","|    reward             | -1.1525393 |\n","|    std                | 1.05       |\n","|    value_loss         | 1.14       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 100       |\n","|    iterations         | 9100      |\n","|    time_elapsed       | 452       |\n","|    total_timesteps    | 45500     |\n","| train/                |           |\n","|    entropy_loss       | -42.4     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 9099      |\n","|    policy_loss        | 17        |\n","|    reward             | 1.5177939 |\n","|    std                | 1.04      |\n","|    value_loss         | 1.34      |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 100      |\n","|    iterations         | 9200     |\n","|    time_elapsed       | 457      |\n","|    total_timesteps    | 46000    |\n","| train/                |          |\n","|    entropy_loss       | -42.4    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 9199     |\n","|    policy_loss        | 22.6     |\n","|    reward             | 6.974023 |\n","|    std                | 1.05     |\n","|    value_loss         | 3.64     |\n","------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 100        |\n","|    iterations         | 9300       |\n","|    time_elapsed       | 463        |\n","|    total_timesteps    | 46500      |\n","| train/                |            |\n","|    entropy_loss       | -42.4      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 9299       |\n","|    policy_loss        | -146       |\n","|    reward             | 0.93126553 |\n","|    std                | 1.05       |\n","|    value_loss         | 13         |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 100         |\n","|    iterations         | 9400        |\n","|    time_elapsed       | 468         |\n","|    total_timesteps    | 47000       |\n","| train/                |             |\n","|    entropy_loss       | -42.5       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 9399        |\n","|    policy_loss        | 83.9        |\n","|    reward             | -0.44344655 |\n","|    std                | 1.05        |\n","|    value_loss         | 4.97        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 100        |\n","|    iterations         | 9500       |\n","|    time_elapsed       | 472        |\n","|    total_timesteps    | 47500      |\n","| train/                |            |\n","|    entropy_loss       | -42.5      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 9499       |\n","|    policy_loss        | -4.48      |\n","|    reward             | 0.20411988 |\n","|    std                | 1.05       |\n","|    value_loss         | 0.83       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 100        |\n","|    iterations         | 9600       |\n","|    time_elapsed       | 477        |\n","|    total_timesteps    | 48000      |\n","| train/                |            |\n","|    entropy_loss       | -42.5      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 9599       |\n","|    policy_loss        | -421       |\n","|    reward             | -1.3227282 |\n","|    std                | 1.05       |\n","|    value_loss         | 101        |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 100         |\n","|    iterations         | 9700        |\n","|    time_elapsed       | 482         |\n","|    total_timesteps    | 48500       |\n","| train/                |             |\n","|    entropy_loss       | -42.5       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 9699        |\n","|    policy_loss        | 80.2        |\n","|    reward             | -0.78597915 |\n","|    std                | 1.05        |\n","|    value_loss         | 3.92        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 100       |\n","|    iterations         | 9800      |\n","|    time_elapsed       | 488       |\n","|    total_timesteps    | 49000     |\n","| train/                |           |\n","|    entropy_loss       | -42.6     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 9799      |\n","|    policy_loss        | 43.2      |\n","|    reward             | 2.5185044 |\n","|    std                | 1.05      |\n","|    value_loss         | 13.7      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 100        |\n","|    iterations         | 9900       |\n","|    time_elapsed       | 493        |\n","|    total_timesteps    | 49500      |\n","| train/                |            |\n","|    entropy_loss       | -42.6      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 9899       |\n","|    policy_loss        | 15.4       |\n","|    reward             | 0.05375599 |\n","|    std                | 1.05       |\n","|    value_loss         | 0.509      |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 100        |\n","|    iterations         | 10000      |\n","|    time_elapsed       | 498        |\n","|    total_timesteps    | 50000      |\n","| train/                |            |\n","|    entropy_loss       | -42.6      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 9999       |\n","|    policy_loss        | 38.1       |\n","|    reward             | -0.6523073 |\n","|    std                | 1.05       |\n","|    value_loss         | 1.6        |\n","--------------------------------------\n","{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n","Using cpu device\n","day: 2892, episode: 20\n","begin_total_asset: 1000000.00\n","end_total_asset: 4491853.57\n","total_reward: 3491853.57\n","total_cost: 5092.04\n","total_trades: 43330\n","Sharpe: 0.812\n","=================================\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 4         |\n","|    fps             | 24        |\n","|    time_elapsed    | 463       |\n","|    total_timesteps | 11572     |\n","| train/             |           |\n","|    actor_loss      | -43.1     |\n","|    critic_loss     | 1.53e+03  |\n","|    learning_rate   | 0.001     |\n","|    n_updates       | 8679      |\n","|    reward          | 2.3630443 |\n","----------------------------------\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 8         |\n","|    fps             | 22        |\n","|    time_elapsed    | 1051      |\n","|    total_timesteps | 23144     |\n","| train/             |           |\n","|    actor_loss      | -16.3     |\n","|    critic_loss     | 21.4      |\n","|    learning_rate   | 0.001     |\n","|    n_updates       | 20251     |\n","|    reward          | 2.3630443 |\n","----------------------------------\n","day: 2892, episode: 30\n","begin_total_asset: 1000000.00\n","end_total_asset: 5359568.24\n","total_reward: 4359568.24\n","total_cost: 1121.84\n","total_trades: 34768\n","Sharpe: 0.902\n","=================================\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 12        |\n","|    fps             | 21        |\n","|    time_elapsed    | 1624      |\n","|    total_timesteps | 34716     |\n","| train/             |           |\n","|    actor_loss      | -15.5     |\n","|    critic_loss     | 10.5      |\n","|    learning_rate   | 0.001     |\n","|    n_updates       | 31823     |\n","|    reward          | 2.3630443 |\n","----------------------------------\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 16        |\n","|    fps             | 21        |\n","|    time_elapsed    | 2193      |\n","|    total_timesteps | 46288     |\n","| train/             |           |\n","|    actor_loss      | -16.6     |\n","|    critic_loss     | 5.01      |\n","|    learning_rate   | 0.001     |\n","|    n_updates       | 43395     |\n","|    reward          | 2.3630443 |\n","----------------------------------\n","{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n","Using cpu device\n","----------------------------------\n","| time/              |           |\n","|    fps             | 111       |\n","|    iterations      | 1         |\n","|    time_elapsed    | 18        |\n","|    total_timesteps | 2048      |\n","| train/             |           |\n","|    reward          | 0.2022352 |\n","----------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 104         |\n","|    iterations           | 2           |\n","|    time_elapsed         | 39          |\n","|    total_timesteps      | 4096        |\n","| train/                  |             |\n","|    approx_kl            | 0.011746932 |\n","|    clip_fraction        | 0.227       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.2       |\n","|    explained_variance   | -0.00391    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 7.43        |\n","|    n_updates            | 10          |\n","|    policy_gradient_loss | -0.0175     |\n","|    reward               | 0.6934402   |\n","|    std                  | 1           |\n","|    value_loss           | 18          |\n","-----------------------------------------\n","day: 2892, episode: 40\n","begin_total_asset: 1000000.00\n","end_total_asset: 3493794.93\n","total_reward: 2493794.93\n","total_cost: 348793.31\n","total_trades: 80947\n","Sharpe: 0.746\n","=================================\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 102        |\n","|    iterations           | 3          |\n","|    time_elapsed         | 59         |\n","|    total_timesteps      | 6144       |\n","| train/                  |            |\n","|    approx_kl            | 0.01642337 |\n","|    clip_fraction        | 0.194      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.3      |\n","|    explained_variance   | 0.00132    |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 63.1       |\n","|    n_updates            | 20         |\n","|    policy_gradient_loss | -0.0126    |\n","|    reward               | -0.7416702 |\n","|    std                  | 1          |\n","|    value_loss           | 105        |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 102        |\n","|    iterations           | 4          |\n","|    time_elapsed         | 79         |\n","|    total_timesteps      | 8192       |\n","| train/                  |            |\n","|    approx_kl            | 0.02138249 |\n","|    clip_fraction        | 0.247      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.3      |\n","|    explained_variance   | -0.00575   |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 36.4       |\n","|    n_updates            | 30         |\n","|    policy_gradient_loss | -0.0179    |\n","|    reward               | 0.3631076  |\n","|    std                  | 1.01       |\n","|    value_loss           | 62.8       |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 103         |\n","|    iterations           | 5           |\n","|    time_elapsed         | 98          |\n","|    total_timesteps      | 10240       |\n","| train/                  |             |\n","|    approx_kl            | 0.012662109 |\n","|    clip_fraction        | 0.138       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.3       |\n","|    explained_variance   | -0.00834    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 8.73        |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.0195     |\n","|    reward               | 3.3220162   |\n","|    std                  | 1.01        |\n","|    value_loss           | 23          |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 103        |\n","|    iterations           | 6          |\n","|    time_elapsed         | 118        |\n","|    total_timesteps      | 12288      |\n","| train/                  |            |\n","|    approx_kl            | 0.01957333 |\n","|    clip_fraction        | 0.161      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.4      |\n","|    explained_variance   | -0.00744   |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 74.5       |\n","|    n_updates            | 50         |\n","|    policy_gradient_loss | -0.019     |\n","|    reward               | 1.9213867  |\n","|    std                  | 1.01       |\n","|    value_loss           | 107        |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 104         |\n","|    iterations           | 7           |\n","|    time_elapsed         | 137         |\n","|    total_timesteps      | 14336       |\n","| train/                  |             |\n","|    approx_kl            | 0.023154177 |\n","|    clip_fraction        | 0.24        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.4       |\n","|    explained_variance   | -0.00131    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 8.23        |\n","|    n_updates            | 60          |\n","|    policy_gradient_loss | -0.0235     |\n","|    reward               | 0.408817    |\n","|    std                  | 1.01        |\n","|    value_loss           | 37.9        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 104         |\n","|    iterations           | 8           |\n","|    time_elapsed         | 156         |\n","|    total_timesteps      | 16384       |\n","| train/                  |             |\n","|    approx_kl            | 0.024907585 |\n","|    clip_fraction        | 0.245       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.5       |\n","|    explained_variance   | -0.0131     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 9.8         |\n","|    n_updates            | 70          |\n","|    policy_gradient_loss | -0.0193     |\n","|    reward               | 0.19197199  |\n","|    std                  | 1.01        |\n","|    value_loss           | 16          |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 104         |\n","|    iterations           | 9           |\n","|    time_elapsed         | 176         |\n","|    total_timesteps      | 18432       |\n","| train/                  |             |\n","|    approx_kl            | 0.022881698 |\n","|    clip_fraction        | 0.243       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.6       |\n","|    explained_variance   | -0.00605    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 10.7        |\n","|    n_updates            | 80          |\n","|    policy_gradient_loss | -0.0255     |\n","|    reward               | 0.8548435   |\n","|    std                  | 1.02        |\n","|    value_loss           | 25.6        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 104         |\n","|    iterations           | 10          |\n","|    time_elapsed         | 195         |\n","|    total_timesteps      | 20480       |\n","| train/                  |             |\n","|    approx_kl            | 0.023161711 |\n","|    clip_fraction        | 0.263       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.7       |\n","|    explained_variance   | 0.00651     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 28.9        |\n","|    n_updates            | 90          |\n","|    policy_gradient_loss | -0.0196     |\n","|    reward               | 0.9222841   |\n","|    std                  | 1.02        |\n","|    value_loss           | 49          |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 105         |\n","|    iterations           | 11          |\n","|    time_elapsed         | 214         |\n","|    total_timesteps      | 22528       |\n","| train/                  |             |\n","|    approx_kl            | 0.023118693 |\n","|    clip_fraction        | 0.222       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.7       |\n","|    explained_variance   | 0.00594     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 17.4        |\n","|    n_updates            | 100         |\n","|    policy_gradient_loss | -0.0161     |\n","|    reward               | 2.4356956   |\n","|    std                  | 1.02        |\n","|    value_loss           | 43          |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 104         |\n","|    iterations           | 12          |\n","|    time_elapsed         | 234         |\n","|    total_timesteps      | 24576       |\n","| train/                  |             |\n","|    approx_kl            | 0.023958836 |\n","|    clip_fraction        | 0.233       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.8       |\n","|    explained_variance   | -0.00075    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 14.1        |\n","|    n_updates            | 110         |\n","|    policy_gradient_loss | -0.017      |\n","|    reward               | -0.22254844 |\n","|    std                  | 1.02        |\n","|    value_loss           | 27.9        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 104         |\n","|    iterations           | 13          |\n","|    time_elapsed         | 255         |\n","|    total_timesteps      | 26624       |\n","| train/                  |             |\n","|    approx_kl            | 0.018528879 |\n","|    clip_fraction        | 0.219       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.8       |\n","|    explained_variance   | 0.00201     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 18.4        |\n","|    n_updates            | 120         |\n","|    policy_gradient_loss | -0.0182     |\n","|    reward               | 0.2280888   |\n","|    std                  | 1.02        |\n","|    value_loss           | 80.2        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 104         |\n","|    iterations           | 14          |\n","|    time_elapsed         | 274         |\n","|    total_timesteps      | 28672       |\n","| train/                  |             |\n","|    approx_kl            | 0.026688026 |\n","|    clip_fraction        | 0.296       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.9       |\n","|    explained_variance   | -0.00042    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 24.9        |\n","|    n_updates            | 130         |\n","|    policy_gradient_loss | -0.0163     |\n","|    reward               | -2.035506   |\n","|    std                  | 1.03        |\n","|    value_loss           | 66.7        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 104         |\n","|    iterations           | 15          |\n","|    time_elapsed         | 294         |\n","|    total_timesteps      | 30720       |\n","| train/                  |             |\n","|    approx_kl            | 0.020515652 |\n","|    clip_fraction        | 0.235       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42         |\n","|    explained_variance   | 0.0174      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 13          |\n","|    n_updates            | 140         |\n","|    policy_gradient_loss | -0.0149     |\n","|    reward               | 2.8172073   |\n","|    std                  | 1.03        |\n","|    value_loss           | 24.2        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 103         |\n","|    iterations           | 16          |\n","|    time_elapsed         | 315         |\n","|    total_timesteps      | 32768       |\n","| train/                  |             |\n","|    approx_kl            | 0.033454318 |\n","|    clip_fraction        | 0.33        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42         |\n","|    explained_variance   | 0.0198      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 11.2        |\n","|    n_updates            | 150         |\n","|    policy_gradient_loss | -0.0191     |\n","|    reward               | -0.42479077 |\n","|    std                  | 1.03        |\n","|    value_loss           | 26.9        |\n","-----------------------------------------\n","day: 2892, episode: 50\n","begin_total_asset: 1000000.00\n","end_total_asset: 2953786.57\n","total_reward: 1953786.57\n","total_cost: 318940.79\n","total_trades: 78240\n","Sharpe: 0.659\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 104         |\n","|    iterations           | 17          |\n","|    time_elapsed         | 334         |\n","|    total_timesteps      | 34816       |\n","| train/                  |             |\n","|    approx_kl            | 0.025805166 |\n","|    clip_fraction        | 0.246       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.1       |\n","|    explained_variance   | 0.0102      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 19.7        |\n","|    n_updates            | 160         |\n","|    policy_gradient_loss | -0.0142     |\n","|    reward               | 0.7863024   |\n","|    std                  | 1.03        |\n","|    value_loss           | 37.9        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 104         |\n","|    iterations           | 18          |\n","|    time_elapsed         | 353         |\n","|    total_timesteps      | 36864       |\n","| train/                  |             |\n","|    approx_kl            | 0.023295712 |\n","|    clip_fraction        | 0.241       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.1       |\n","|    explained_variance   | 0.0154      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 25.2        |\n","|    n_updates            | 170         |\n","|    policy_gradient_loss | -0.0149     |\n","|    reward               | -0.28178445 |\n","|    std                  | 1.04        |\n","|    value_loss           | 33.6        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 104         |\n","|    iterations           | 19          |\n","|    time_elapsed         | 373         |\n","|    total_timesteps      | 38912       |\n","| train/                  |             |\n","|    approx_kl            | 0.023656959 |\n","|    clip_fraction        | 0.233       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.2       |\n","|    explained_variance   | -0.00123    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 2.94        |\n","|    n_updates            | 180         |\n","|    policy_gradient_loss | -0.0195     |\n","|    reward               | -0.7872464  |\n","|    std                  | 1.04        |\n","|    value_loss           | 10.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 104         |\n","|    iterations           | 20          |\n","|    time_elapsed         | 393         |\n","|    total_timesteps      | 40960       |\n","| train/                  |             |\n","|    approx_kl            | 0.020284474 |\n","|    clip_fraction        | 0.225       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.2       |\n","|    explained_variance   | 0.0222      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 11.9        |\n","|    n_updates            | 190         |\n","|    policy_gradient_loss | -0.0182     |\n","|    reward               | -0.8021191  |\n","|    std                  | 1.04        |\n","|    value_loss           | 26.8        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 104         |\n","|    iterations           | 21          |\n","|    time_elapsed         | 413         |\n","|    total_timesteps      | 43008       |\n","| train/                  |             |\n","|    approx_kl            | 0.021958068 |\n","|    clip_fraction        | 0.223       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.3       |\n","|    explained_variance   | -0.00995    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 40.5        |\n","|    n_updates            | 200         |\n","|    policy_gradient_loss | -0.0139     |\n","|    reward               | -7.0020127  |\n","|    std                  | 1.04        |\n","|    value_loss           | 83.2        |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 103        |\n","|    iterations           | 22         |\n","|    time_elapsed         | 434        |\n","|    total_timesteps      | 45056      |\n","| train/                  |            |\n","|    approx_kl            | 0.02203301 |\n","|    clip_fraction        | 0.204      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -42.3      |\n","|    explained_variance   | -0.00874   |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 23.5       |\n","|    n_updates            | 210        |\n","|    policy_gradient_loss | -0.0148    |\n","|    reward               | 2.1782522  |\n","|    std                  | 1.04       |\n","|    value_loss           | 46.4       |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 103         |\n","|    iterations           | 23          |\n","|    time_elapsed         | 454         |\n","|    total_timesteps      | 47104       |\n","| train/                  |             |\n","|    approx_kl            | 0.030835021 |\n","|    clip_fraction        | 0.247       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.4       |\n","|    explained_variance   | 0.00773     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 30.4        |\n","|    n_updates            | 220         |\n","|    policy_gradient_loss | -0.0166     |\n","|    reward               | -0.22798498 |\n","|    std                  | 1.05        |\n","|    value_loss           | 56          |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 103        |\n","|    iterations           | 24         |\n","|    time_elapsed         | 473        |\n","|    total_timesteps      | 49152      |\n","| train/                  |            |\n","|    approx_kl            | 0.03233183 |\n","|    clip_fraction        | 0.267      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -42.5      |\n","|    explained_variance   | 0.0228     |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 13.4       |\n","|    n_updates            | 230        |\n","|    policy_gradient_loss | -0.0115    |\n","|    reward               | 4.4472632  |\n","|    std                  | 1.05       |\n","|    value_loss           | 35.1       |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 103         |\n","|    iterations           | 25          |\n","|    time_elapsed         | 495         |\n","|    total_timesteps      | 51200       |\n","| train/                  |             |\n","|    approx_kl            | 0.027862426 |\n","|    clip_fraction        | 0.26        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.5       |\n","|    explained_variance   | 0.0412      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 17.1        |\n","|    n_updates            | 240         |\n","|    policy_gradient_loss | -0.00885    |\n","|    reward               | -0.9694052  |\n","|    std                  | 1.05        |\n","|    value_loss           | 40.7        |\n","-----------------------------------------\n","{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n","Using cpu device\n","day: 2892, episode: 60\n","begin_total_asset: 1000000.00\n","end_total_asset: 4080725.60\n","total_reward: 3080725.60\n","total_cost: 999.00\n","total_trades: 40464\n","Sharpe: 0.695\n","=================================\n","---------------------------------\n","| time/              |          |\n","|    episodes        | 4        |\n","|    fps             | 28       |\n","|    time_elapsed    | 399      |\n","|    total_timesteps | 11572    |\n","| train/             |          |\n","|    actor_loss      | 66.2     |\n","|    critic_loss     | 1.57e+03 |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 8679     |\n","|    reward          | 2.151094 |\n","---------------------------------\n","---------------------------------\n","| time/              |          |\n","|    episodes        | 8        |\n","|    fps             | 24       |\n","|    time_elapsed    | 928      |\n","|    total_timesteps | 23144    |\n","| train/             |          |\n","|    actor_loss      | 32       |\n","|    critic_loss     | 318      |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 20251    |\n","|    reward          | 2.151094 |\n","---------------------------------\n","{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n","Using cpu device\n","day: 2892, episode: 70\n","begin_total_asset: 1000000.00\n","end_total_asset: 4400764.27\n","total_reward: 3400764.27\n","total_cost: 24896.21\n","total_trades: 44669\n","Sharpe: 0.629\n","=================================\n","---------------------------------\n","| time/              |          |\n","|    episodes        | 4        |\n","|    fps             | 19       |\n","|    time_elapsed    | 582      |\n","|    total_timesteps | 11572    |\n","| train/             |          |\n","|    actor_loss      | 963      |\n","|    critic_loss     | 97.3     |\n","|    ent_coef        | 0.188    |\n","|    ent_coef_loss   | -71.6    |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 11471    |\n","|    reward          | 5.794713 |\n","---------------------------------\n","---------------------------------\n","| time/              |          |\n","|    episodes        | 8        |\n","|    fps             | 19       |\n","|    time_elapsed    | 1173     |\n","|    total_timesteps | 23144    |\n","| train/             |          |\n","|    actor_loss      | 453      |\n","|    critic_loss     | 496      |\n","|    ent_coef        | 0.0592   |\n","|    ent_coef_loss   | -117     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 23043    |\n","|    reward          | 7.382384 |\n","---------------------------------\n","day: 2892, episode: 80\n","begin_total_asset: 1000000.00\n","end_total_asset: 5040580.08\n","total_reward: 4040580.08\n","total_cost: 6120.61\n","total_trades: 48959\n","Sharpe: 0.786\n","=================================\n","---------------------------------\n","| time/              |          |\n","|    episodes        | 12       |\n","|    fps             | 19       |\n","|    time_elapsed    | 1775     |\n","|    total_timesteps | 34716    |\n","| train/             |          |\n","|    actor_loss      | 206      |\n","|    critic_loss     | 25.5     |\n","|    ent_coef        | 0.019    |\n","|    ent_coef_loss   | -131     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 34615    |\n","|    reward          | 7.158794 |\n","---------------------------------\n","---------------------------------\n","| time/              |          |\n","|    episodes        | 16       |\n","|    fps             | 19       |\n","|    time_elapsed    | 2370     |\n","|    total_timesteps | 46288    |\n","| train/             |          |\n","|    actor_loss      | 106      |\n","|    critic_loss     | 7.44     |\n","|    ent_coef        | 0.00626  |\n","|    ent_coef_loss   | -108     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 46187    |\n","|    reward          | 7.099692 |\n","---------------------------------\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 20        |\n","|    fps             | 19        |\n","|    time_elapsed    | 2961      |\n","|    total_timesteps | 57860     |\n","| train/             |           |\n","|    actor_loss      | 55.2      |\n","|    critic_loss     | 5.89      |\n","|    ent_coef        | 0.00252   |\n","|    ent_coef_loss   | -16.6     |\n","|    learning_rate   | 0.0001    |\n","|    n_updates       | 57759     |\n","|    reward          | 5.9643593 |\n","----------------------------------\n","trade.head():          date   tic        open        high         low       close  \\\n","0  2020-07-01  AAPL   91.279999   91.839996   90.977501   89.631210   \n","0  2020-07-01  AMGN  235.520004  256.230011  232.580002  238.313568   \n","0  2020-07-01   AXP   95.250000   96.959999   93.639999   91.394157   \n","0  2020-07-01    BA  185.880005  190.610001  180.039993  180.320007   \n","0  2020-07-01   CAT  129.380005  129.399994  125.879997  119.020714   \n","\n","        volume  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n","0  110737200.0  2.0  3.005436   92.417425   79.936132  62.807142  107.496672   \n","0    6575800.0  2.0  3.608526  230.616460  198.678635  61.279652  271.208776   \n","0    3301000.0  2.0 -0.386236  109.593883   87.099642  48.504815  -66.313257   \n","0   49036700.0  2.0  5.443193  220.721139  160.932863  50.925771   24.220608   \n","0    2807800.0  2.0  1.255425  128.858560  111.820860  52.865419   35.668231   \n","\n","       dx_30  close_30_sma  close_60_sma        atr        tema        vix  \\\n","0  29.730532     83.678530     77.481209   2.896537   89.621015  28.620001   \n","0  46.806139    213.212110    214.276892  19.759237  232.599971  28.620001   \n","0   3.142448     96.513644     90.013762   5.311152   91.211788  28.620001   \n","0  15.932920    176.472335    155.614168  13.520082  182.210854  28.620001   \n","0  14.457404    117.798663    112.110446   8.944440  119.151878  28.620001   \n","\n","   turbulence  \n","0   53.068141  \n","0   53.068141  \n","0   53.068141  \n","0   53.068141  \n","0   53.068141  \n","hit end!\n","df_account_value.shape: (337, 2)\n","df_account_value.tail():            date  account_value\n","332  2021-10-25   1.240130e+06\n","333  2021-10-26   1.238645e+06\n","334  2021-10-27   1.239325e+06\n","335  2021-10-28   1.250199e+06\n","336  2021-10-29   1.257275e+06\n","df_actions.head():             AAPL  AMGN  AXP  BA  CAT  CRM  CSCO  CVX  DIS  GS  ...  MRK  MSFT  \\\n","date                                                           ...              \n","2020-07-01     0    96    0   0   30    0     0    0   95  94  ...    0    20   \n","2020-07-02     0    96    0   0   30    0     0    0   95  94  ...    0    20   \n","2020-07-06     0    96    0   0   30    0     0    0   95  94  ...    0    20   \n","2020-07-07     0    96    0   0   30    0     0    0   95  94  ...    0    20   \n","2020-07-08     0    96    0   0   30    0     0    0   95  94  ...    0    20   \n","\n","            NKE  PG  TRV  UNH   V  VZ  WBA  WMT  \n","date                                             \n","2020-07-01   86  90    0   81  74   0    0   86  \n","2020-07-02   86  90    0   81  74   0    0   86  \n","2020-07-06   86  90    0   81  74   0    0   86  \n","2020-07-07   86  90    0   81  74   0    0   86  \n","2020-07-08   86  90    0   81  74   0    0   86  \n","\n","[5 rows x 29 columns]\n","==============Get Backtest Results===========\n","Annual return          0.186728\n","Cumulative returns     0.257275\n","Annual volatility      0.139031\n","Sharpe ratio           1.304756\n","Calmar ratio           2.381766\n","Stability              0.847394\n","Max drawdown          -0.078399\n","Omega ratio            1.248119\n","Sortino ratio          1.939245\n","Skew                        NaN\n","Kurtosis                    NaN\n","Tail ratio             1.204694\n","Daily value at risk   -0.016796\n","dtype: float64\n","==============Get Baseline Stats===========\n","[*********************100%***********************]  1 of 1 completed\n","Shape of DataFrame:  (336, 8)\n","Annual return          0.279047\n","Cumulative returns     0.388402\n","Annual volatility      0.139129\n","Sharpe ratio           1.844560\n","Calmar ratio           3.124551\n","Stability              0.918675\n","Max drawdown          -0.089308\n","Omega ratio            1.358960\n","Sortino ratio          2.734872\n","Skew                        NaN\n","Kurtosis                    NaN\n","Tail ratio             1.052781\n","Daily value at risk   -0.016510\n","dtype: float64\n","==============Compare to DJIA===========\n","[*********************100%***********************]  1 of 1 completed\n","Shape of DataFrame:  (336, 8)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2020-07-01</td></tr>\n","    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2021-10-29</td></tr>\n","    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>16</td></tr>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Backtest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Annual return</th>\n","      <td>18.673%</td>\n","    </tr>\n","    <tr>\n","      <th>Cumulative returns</th>\n","      <td>25.727%</td>\n","    </tr>\n","    <tr>\n","      <th>Annual volatility</th>\n","      <td>13.903%</td>\n","    </tr>\n","    <tr>\n","      <th>Sharpe ratio</th>\n","      <td>1.30</td>\n","    </tr>\n","    <tr>\n","      <th>Calmar ratio</th>\n","      <td>2.38</td>\n","    </tr>\n","    <tr>\n","      <th>Stability</th>\n","      <td>0.85</td>\n","    </tr>\n","    <tr>\n","      <th>Max drawdown</th>\n","      <td>-7.84%</td>\n","    </tr>\n","    <tr>\n","      <th>Omega ratio</th>\n","      <td>1.25</td>\n","    </tr>\n","    <tr>\n","      <th>Sortino ratio</th>\n","      <td>1.94</td>\n","    </tr>\n","    <tr>\n","      <th>Skew</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>Kurtosis</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>Tail ratio</th>\n","      <td>1.20</td>\n","    </tr>\n","    <tr>\n","      <th>Daily value at risk</th>\n","      <td>-1.68%</td>\n","    </tr>\n","    <tr>\n","      <th>Alpha</th>\n","      <td>-0.02</td>\n","    </tr>\n","    <tr>\n","      <th>Beta</th>\n","      <td>0.78</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>Worst drawdown periods</th>\n","      <th>Net drawdown in %</th>\n","      <th>Peak date</th>\n","      <th>Valley date</th>\n","      <th>Recovery date</th>\n","      <th>Duration</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7.84</td>\n","      <td>2021-08-16</td>\n","      <td>2021-09-30</td>\n","      <td>NaT</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7.57</td>\n","      <td>2020-10-07</td>\n","      <td>2020-10-30</td>\n","      <td>2020-11-16</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6.20</td>\n","      <td>2021-01-08</td>\n","      <td>2021-03-04</td>\n","      <td>2021-03-15</td>\n","      <td>47</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.73</td>\n","      <td>2021-05-07</td>\n","      <td>2021-06-18</td>\n","      <td>2021-06-25</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4.54</td>\n","      <td>2020-09-02</td>\n","      <td>2020-09-24</td>\n","      <td>2020-10-05</td>\n","      <td>24</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>Stress Events</th>\n","      <th>mean</th>\n","      <th>min</th>\n","      <th>max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>New Normal</th>\n","      <td>0.07%</td>\n","      <td>-3.64%</td>\n","      <td>4.64%</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-13ee00bee5d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Stock_NeurIPS2018_SB3.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2312\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2314\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2315\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-52>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    825\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                         \u001b[0;31m# regular execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m                         \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'i'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    811\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m                             runner(filename, prog_ns, prog_ns,\n\u001b[0;32m--> 813\u001b[0;31m                                     exit_ignore=exit_ignore)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m't'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mmpl_execfile\u001b[0;34m(fname, *where, **kw)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# make rendering call now, if the user tried to do it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_if_interactive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_if_interactive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'called'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xNkDEW5VBWoR"},"execution_count":null,"outputs":[]}]}
